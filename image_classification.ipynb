{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMS4030A/COMS7047A- ADVANCED COMPUTATION AND MACHINE LEARNING\n",
    "## Brain Tumor Detection using a CNN\n",
    "Tumi Jourdan ~ 2180153, \n",
    "Luca von Mayer ~ 2427051, \n",
    "Mohammad Zaid Moonsamy ~ 2433079, \n",
    "Shakeel Malagas ~ 2424161\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import umap\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, cohen_kappa_score\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adagrad, RMSprop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting directories\n",
    "meningioma_dir = 'dataset/1'\n",
    "glioma_dir = 'dataset/2'\n",
    "pituitary_dir = 'dataset/3'\n",
    "\n",
    "\n",
    "meningioma_images = [os.path.join(meningioma_dir, img) for img in os.listdir(meningioma_dir) if img.endswith('.jpg') or img.endswith('.JPG') or img.endswith('.png') or img.endswith('.PNG') or img.endswith('.JPEG') or img.endswith('.jpeg')]\n",
    "glioma_images = [os.path.join(glioma_dir, img) for img in os.listdir(glioma_dir) if img.endswith('.jpg') or img.endswith('.JPG') or img.endswith('.png') or img.endswith('.PNG') or img.endswith('.JPEG') or img.endswith('.jpeg')]\n",
    "pituitary_images = [os.path.join(pituitary_dir, img) for img in os.listdir(pituitary_dir) if img.endswith('.jpg') or img.endswith('.JPG') or img.endswith('.png') or img.endswith('.PNG') or img.endswith('.JPEG') or img.endswith('.jpeg')]\n",
    "\n",
    "# combining the normal images and the tumor images\n",
    "data = np.concatenate([meningioma_images, glioma_images, pituitary_images])\n",
    "\n",
    "# printing some informative dataset information\n",
    "print(\"The dataset contains \", len(meningioma_images), \"meningioma tumor images\")\n",
    "print(\"The dataset contains \", len(glioma_images), \"glioma tumor images\")\n",
    "print(\"The dataset contains \", len(pituitary_images), \"pituitary tumor images\")\n",
    "print(\"The merged dataset contains \", len(data), \"image samples\")\n",
    "print(\"The data list contains the image samples as files: \", data[0:5], \"&\", data[-5:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing 10 meningioma tumor image samples\n",
    "print(\"The meningioma tumor image samples:\")\n",
    "plt.figure(figsize=(6, 3))\n",
    "for i, img_path in enumerate(meningioma_images[:10], 1):\n",
    "    image = Image.open(img_path)\n",
    "    plt.subplot(2, 5, i)\n",
    "    plt.imshow(image)\n",
    "    plt.title(os.path.basename(img_path))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Printing 10 glioma tumor image samples\n",
    "print(\"The glioma tumor image samples:\")\n",
    "plt.figure(figsize=(6, 3))\n",
    "for i, img_path in enumerate(glioma_images[:10], 1):\n",
    "    image = Image.open(img_path)\n",
    "    plt.subplot(2, 5, i)\n",
    "    plt.imshow(image)\n",
    "    plt.title(os.path.basename(img_path))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Printing 10 pituitary tumor image samples\n",
    "print(\"The pituitary tumor image samples:\")\n",
    "plt.figure(figsize=(6, 3))\n",
    "for i, img_path in enumerate(pituitary_images[:10], 1):\n",
    "    image = Image.open(img_path)\n",
    "    plt.subplot(2, 5, i)\n",
    "    plt.imshow(image)\n",
    "    plt.title(os.path.basename(img_path))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting the graph displaying the balance of different types of tumors in the dataset\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(0, len(meningioma_images),color='green',  label='Value 1')\n",
    "plt.bar(1, len(glioma_images),color='red', label='Value 2')\n",
    "plt.bar(2, len(pituitary_images),color='blue', label='Value 3')\n",
    "plt.xlabel('Image dataset')\n",
    "plt.ylabel('Size')\n",
    "plt.title('Data Balance / Imbalance Check')\n",
    "plt.xticks([0, 1, 2], ['Meningioma Tumor', 'Glioma Tumor' , 'Pituitary Tumor'])  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image Cropping Function and Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cropping function\n",
    "def crop_brain_image(image):\n",
    "    \n",
    "    # Converting the image to grayscale and blurring it\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    threshold = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "    threshold = cv2.erode(threshold, None, iterations=2)\n",
    "    threshold = cv2.dilate(threshold, None, iterations=2)\n",
    "\n",
    "    # Finding contours in the thresholded image and then choosing the largest\n",
    "    contours = cv2.findContours(threshold.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    extreme_left = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extreme_right = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    extreme_top = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extreme_bottom = tuple(c[c[:, :, 1].argmax()][0])\n",
    "    \n",
    "    new_image = image[extreme_top[1]:extreme_bottom[1], extreme_left[0]:extreme_right[0]]            \n",
    "    \n",
    "    return new_image\n",
    "\n",
    "# Cropping an example image from the meningioma dataset\n",
    "prior_image = cv2.imread('./dataset/1/2307.png')\n",
    "cropped_image = crop_brain_image(prior_image)\n",
    "\n",
    "# Visualising the cropping results\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(prior_image)\n",
    "plt.tick_params(axis='both', which='both', top=False, bottom=False, left=False, right=False,labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "plt.title('Original Image')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cropped_image)\n",
    "plt.tick_params(axis='both', which='both',top=False, bottom=False, left=False, right=False,labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "plt.title('Cropped Image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image Cropping, Resizing and Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The preprocessing function that performs croppin, resizing and normalisation on all images\n",
    "def preprocess_images(dir):\n",
    "    final_images = []\n",
    "    for file in os.listdir(dir):\n",
    "        img_path = os.path.join(dir, file)\n",
    "        \n",
    "        if os.path.isfile(img_path):\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            # Cropping the images using the cropping function above\n",
    "            cropped_img = crop_brain_image(img)\n",
    "            \n",
    "            # Resizing the image using cv2\n",
    "            resized_img = cv2.resize(cropped_img, (224, 224))\n",
    "            \n",
    "            # Normalising the resized image\n",
    "            normalized_img = resized_img / 255.0\n",
    "            \n",
    "            final_images.append(normalized_img)\n",
    "    return final_images\n",
    "\n",
    "# Function to display the images\n",
    "def show_images(images, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    for i in range(min(5, len(images))):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(title, y=0.7)  \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "meningioma = preprocess_images('./dataset/1')\n",
    "glioma = preprocess_images('./dataset/2')\n",
    "pituitary = preprocess_images('./dataset/3')\n",
    "\n",
    "# visualising the images after the preprocessing\n",
    "show_images(meningioma, 'Meningioma Tumor Images')\n",
    "show_images(glioma, 'Glioma Tumor Images')\n",
    "show_images(pituitary, 'Pituitary Tumor Images')\n",
    "\n",
    "# Printing the shape of images after the resizing and normalisation\n",
    "print(\"Shape of first 5 meningioma images:\", [img.shape for img in meningioma[:5]])\n",
    "print(\"Shape of first 5 glioma images:\", [img.shape for img in glioma[:5]])\n",
    "print(\"Shape of first 5 pituitary images:\", [img.shape for img in pituitary[:5]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Target Appending, Data Splitting and Input Batches for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the numpy targets with 0s, 1s and 2s\n",
    "meningioma_targets = np.zeros(len(meningioma))\n",
    "glioma_targets = np.ones(len(glioma))\n",
    "pituitary_targets = np.full(len(pituitary), 2)\n",
    "\n",
    "# the data and targets finalisation - converting to numpy arrays\n",
    "data = meningioma + glioma + pituitary\n",
    "targets = np.concatenate((meningioma_targets, glioma_targets, pituitary_targets), axis=0)\n",
    "X = np.array(data)\n",
    "Y = np.array(targets)\n",
    "\n",
    "# Data Augmentation\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_resampled, Y_resampled = oversampler.fit_resample(X.reshape(X.shape[0], -1), Y)\n",
    "X_resampled = X_resampled.reshape(-1, 224, 224, 3)\n",
    "\n",
    "# Plotting the graph displaying the balance of different types of tumors in the resampled dataset\n",
    "unique, counts = np.unique(Y_resampled, return_counts=True)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(range(len(unique)), counts, color=['green', 'red', 'blue'], label=['Meningioma', 'Glioma', 'Pituitary'])\n",
    "plt.xlabel('Tumor Type')\n",
    "plt.ylabel('Size')\n",
    "plt.title('Resampled Data Balance')\n",
    "plt.xticks(range(len(unique)), ['Meningioma', 'Glioma', 'Pituitary'])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Splitting the training and testing data and making sure that the data is shuffled \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_resampled, Y_resampled, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of Y_train:\", Y_train.shape)\n",
    "print(\"Shape of Y_test:\", Y_test.shape)\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "test = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "\n",
    "# Splitting the train data into train and validation\n",
    "validation_size = int(0.1 * len(X_train))\n",
    "train = train.skip(validation_size)\n",
    "val = train.take(validation_size)\n",
    "\n",
    "print(\"Train dataset size:\", len(X_train) - validation_size)\n",
    "print(\"Validation dataset size:\", validation_size)\n",
    "print(\"Test dataset size:\", len(X_test))\n",
    "\n",
    "# Input will be fed in batches of 28\n",
    "BATCH_SIZE = 25\n",
    "train = train.batch(BATCH_SIZE)\n",
    "test = test.batch(BATCH_SIZE)\n",
    "val = val.batch(BATCH_SIZE)\n",
    "\n",
    "train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making use of a sequential model: layers are added one by one\n",
    "model = Sequential()\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "# Adding convolutional, pooling, flattening, dropout and dense layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3), padding='valid'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# printing the summary model architecture\n",
    "model.summary()\n",
    "\n",
    "# Create an instance of the Adam optimizer with a custom learning rate\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.99)\n",
    "\n",
    "# Using adam w optimiser with sparse categorical cross entropy for multiclass classification\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# training\n",
    "training_results = model.fit(train, validation_data=val, epochs=30, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing and Evaluation of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(test)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_prediction = model.predict(test)\n",
    "y_prediction_classes = np.argmax(y_prediction, axis=1)\n",
    "\n",
    "# Calculating and printing the classification report which includes precision, f1-score and more\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, y_prediction_classes, target_names=['Meningioma', 'Glioma', 'Pituitary']))\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_matrix = tf.math.confusion_matrix(Y_test, y_prediction_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix.numpy())\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix.numpy(), annot=True, fmt='d', cmap='Blues', xticklabels=['Meningioma', 'Glioma', 'Pituitary'], yticklabels=['Meningioma', 'Glioma', 'Pituitary'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Model accuracy graph\n",
    "plt.figure()\n",
    "plt.plot(training_results.history['accuracy'])\n",
    "plt.plot(training_results.history['val_accuracy'])\n",
    "plt.legend(['Train Accuracy', 'Validation Accuracy'], loc='upper right')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Model loss graph\n",
    "plt.figure()\n",
    "plt.plot(training_results.history['loss'])\n",
    "plt.plot(training_results.history['val_loss'])\n",
    "plt.legend(['Train Loss', 'Validation Loss'], loc='upper right')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Evaluation with k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "data = meningioma + glioma + pituitary\n",
    "targets = np.concatenate((meningioma_targets, glioma_targets, pituitary_targets), axis=0)\n",
    "X = np.array(data)\n",
    "Y = np.array(targets)\n",
    "\n",
    "# Oversampling the data\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_resampled, Y_resampled = oversampler.fit_resample(X.reshape(X.shape[0], -1), Y)\n",
    "X_resampled = X_resampled.reshape(-1, 224, 224, 3)\n",
    "\n",
    "# Implementing the k-fold Cross Validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "loss_scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "for train_index, test_index in kfold.split(X_resampled, Y_resampled):\n",
    "    X_train, X_test = X_resampled[train_index], X_resampled[test_index]\n",
    "    Y_train, Y_test = Y_resampled[train_index], Y_resampled[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3), padding='valid'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    training_results = model.fit(X_train, Y_train, epochs=10, batch_size=25, validation_split=0.2, verbose=1)\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
    "    print(f'Score for fold {fold_no}: loss of {test_loss:.4f}; accuracy of {test_accuracy:.4f}')\n",
    "    y_prediction = model.predict(X_test)\n",
    "    y_prediction_classes = np.argmax(y_prediction, axis=1)\n",
    "\n",
    "    # Calculating and printing the classification report\n",
    "    print(f\"Classification Report for fold {fold_no}:\")\n",
    "    print(classification_report(Y_test, y_prediction_classes, target_names=['Meningioma', 'Glioma', 'Pituitary']))\n",
    "\n",
    "    # Confusion matrix\n",
    "    confusion_mtx = confusion_matrix(Y_test, y_prediction_classes)\n",
    "    print(f\"Confusion Matrix for fold {fold_no}:\")\n",
    "    print(confusion_mtx)\n",
    "\n",
    "\n",
    "    # Calculate the metrics\n",
    "    accuracy = accuracy_score(Y_test, y_prediction_classes)\n",
    "    precision = precision_score(Y_test, y_prediction_classes, average='weighted')\n",
    "    recall = recall_score(Y_test, y_prediction_classes, average='weighted')\n",
    "    f1 = f1_score(Y_test, y_prediction_classes, average='weighted')\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    loss_scores.append(test_loss)\n",
    "    confusion_matrices.append(confusion_mtx)\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Displaying the average metrics\n",
    "print('\\nAverage scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(accuracy_scores):.4f} (+- {np.std(accuracy_scores):.4f})')\n",
    "print(f'> Precision: {np.mean(precision_scores):.4f} (+- {np.std(precision_scores):.4f})')\n",
    "print(f'> Recall: {np.mean(recall_scores):.4f} (+- {np.std(recall_scores):.4f})')\n",
    "print(f'> F1 Score: {np.mean(f1_scores):.4f} (+- {np.std(f1_scores):.4f})')\n",
    "print(f'> Loss: {np.mean(loss_scores):.4f} (+- {np.std(loss_scores):.4f})')\n",
    "\n",
    "# Calculating the average confusion matrix\n",
    "avg_cm = np.mean(confusion_matrices, axis=0).astype(int)\n",
    "\n",
    "print('\\nAverage Confusion Matrix:')\n",
    "print(avg_cm)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(avg_cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Meningioma', 'Glioma', 'Pituitary'],\n",
    "            yticklabels=['Meningioma', 'Glioma', 'Pituitary'])\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Average Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
